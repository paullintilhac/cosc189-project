Epoch, training loss, validation loss, validation accuracy, 
1,  2.376351, 		2.310527, 		0.105000, 
2,  2.297224, 		2.296479, 		0.164000, 
3,  2.297831, 		2.285481, 		0.180000, 
4,  2.284133, 		2.277378, 		0.192000, 
5,  2.276035, 		2.271398, 		0.250000, 
6,  2.268939, 		2.262883, 		0.205000, 
7,  2.262048, 		2.256018, 		0.269000, 
8,  2.254325, 		2.247665, 		0.282000, 
9,  2.246787, 		2.240445, 		0.316000, 
10,  2.238613, 		2.232021, 		0.378000, 
11,  2.230789, 		2.223331, 		0.389000, 
12,  2.221404, 		2.214574, 		0.424000, 
13,  2.212649, 		2.205518, 		0.449000, 
14,  2.203024, 		2.195330, 		0.497000, 
15,  2.192919, 		2.185118, 		0.520000, 
16,  2.182465, 		2.173552, 		0.512000, 
17,  2.171237, 		2.161921, 		0.535000, 
18,  2.158877, 		2.148753, 		0.550000, 
19,  2.146243, 		2.135930, 		0.577000, 
20,  2.132972, 		2.121739, 		0.589000, 
21,  2.118025, 		2.106416, 		0.605000, 
22,  2.102432, 		2.089584, 		0.601000, 
23,  2.086062, 		2.072456, 		0.606000, 
24,  2.067822, 		2.053687, 		0.630000, 
25,  2.049465, 		2.033707, 		0.638000, 
26,  2.028486, 		2.012084, 		0.625000, 
27,  2.007080, 		1.989724, 		0.642000, 
28,  1.984999, 		1.966315, 		0.643000, 
29,  1.960422, 		1.940508, 		0.645000, 
30,  1.934819, 		1.913601, 		0.649000, 
31,  1.907937, 		1.885885, 		0.655000, 
32,  1.879875, 		1.856314, 		0.636000, 
33,  1.850809, 		1.826516, 		0.664000, 
34,  1.819891, 		1.795345, 		0.662000, 
35,  1.789125, 		1.762668, 		0.655000, 
36,  1.756881, 		1.729773, 		0.682000, 
37,  1.723630, 		1.696226, 		0.666000, 
38,  1.690758, 		1.661874, 		0.663000, 
39,  1.656752, 		1.627922, 		0.667000, 
40,  1.623261, 		1.593860, 		0.669000, 
41,  1.589479, 		1.559896, 		0.687000, 
42,  1.555864, 		1.526084, 		0.687000, 
43,  1.522492, 		1.493420, 		0.700000, 
44,  1.489867, 		1.460203, 		0.705000, 
45,  1.457616, 		1.428208, 		0.697000, 
46,  1.426481, 		1.397505, 		0.715000, 
47,  1.395602, 		1.367139, 		0.719000, 
48,  1.365715, 		1.337923, 		0.720000, 
49,  1.336898, 		1.309683, 		0.725000, 
50,  1.308639, 		1.282252, 		0.726000, 
51,  1.281659, 		1.255374, 		0.726000, 
52,  1.255194, 		1.229986, 		0.731000, 
53,  1.229785, 		1.205293, 		0.741000, 
54,  1.205348, 		1.181377, 		0.736000, 
55,  1.181989, 		1.159066, 		0.738000, 
56,  1.159476, 		1.137028, 		0.748000, 
57,  1.137136, 		1.116528, 		0.741000, 
58,  1.116166, 		1.095987, 		0.742000, 
59,  1.096030, 		1.076246, 		0.745000, 
60,  1.076344, 		1.058081, 		0.749000, 
61,  1.057535, 		1.040190, 		0.751000, 
62,  1.039483, 		1.022636, 		0.754000, 
63,  1.021979, 		1.006161, 		0.755000, 
64,  1.005472, 		0.990350, 		0.758000, 
65,  0.989112, 		0.974838, 		0.765000, 
66,  0.973316, 		0.960263, 		0.767000, 
67,  0.958388, 		0.945853, 		0.770000, 
68,  0.943609, 		0.931861, 		0.764000, 
69,  0.929866, 		0.918576, 		0.777000, 
70,  0.915675, 		0.905562, 		0.772000, 
71,  0.902446, 		0.893089, 		0.772000, 
72,  0.889839, 		0.881300, 		0.780000, 
73,  0.877245, 		0.869564, 		0.782000, 
74,  0.865157, 		0.857805, 		0.784000, 
75,  0.853202, 		0.847073, 		0.783000, 
76,  0.841960, 		0.836493, 		0.792000, 
77,  0.830967, 		0.825763, 		0.790000, 
78,  0.820047, 		0.815573, 		0.796000, 
79,  0.809480, 		0.805963, 		0.795000, 
80,  0.799168, 		0.796458, 		0.800000, 
81,  0.789261, 		0.787105, 		0.801000, 
82,  0.779474, 		0.778070, 		0.799000, 
83,  0.770149, 		0.769226, 		0.805000, 
84,  0.760890, 		0.760620, 		0.806000, 
85,  0.751713, 		0.752298, 		0.808000, 
86,  0.743165, 		0.744002, 		0.808000, 
87,  0.734370, 		0.736073, 		0.811000, 
88,  0.725901, 		0.728389, 		0.817000, 
89,  0.717744, 		0.720688, 		0.817000, 
90,  0.709703, 		0.712908, 		0.817000, 
91,  0.702097, 		0.705955, 		0.820000, 
92,  0.694130, 		0.699006, 		0.821000, 
93,  0.686770, 		0.691794, 		0.822000, 
94,  0.679349, 		0.684833, 		0.822000, 
95,  0.672367, 		0.678381, 		0.822000, 
96,  0.665318, 		0.672399, 		0.825000, 
97,  0.658447, 		0.666105, 		0.825000, 
98,  0.651553, 		0.659802, 		0.826000, 
99,  0.645012, 		0.653527, 		0.825000, 
100,  0.638612, 		0.647738, 		0.825000, 
Epoch, training loss, validation loss, validation accuracy, 
1,  2.391114, 		2.307266, 		0.117000, 
2,  2.305877, 		2.315344, 		0.096000, 
3,  2.311549, 		2.306312, 		0.127000, 
4,  2.302304, 		2.297128, 		0.119000, 
5,  2.300795, 		2.297382, 		0.119000, 
6,  2.300735, 		2.297970, 		0.117000, 
7,  2.300257, 		2.298172, 		0.119000, 
8,  2.300064, 		2.297720, 		0.108000, 
9,  2.299919, 		2.297742, 		0.119000, 
10,  2.300116, 		2.297367, 		0.119000, 
11,  2.299762, 		2.297564, 		0.119000, 
12,  2.300066, 		2.297855, 		0.121000, 
13,  2.299934, 		2.297198, 		0.119000, 
14,  2.299897, 		2.297443, 		0.119000, 
15,  2.299460, 		2.297641, 		0.119000, 
16,  2.299299, 		2.297242, 		0.119000, 
17,  2.299493, 		2.297327, 		0.152000, 
18,  2.299555, 		2.297239, 		0.115000, 
19,  2.299268, 		2.296700, 		0.119000, 
20,  2.299711, 		2.297435, 		0.145000, 
21,  2.299200, 		2.297128, 		0.139000, 
22,  2.299158, 		2.297000, 		0.119000, 
23,  2.299108, 		2.296614, 		0.133000, 
24,  2.299037, 		2.296627, 		0.119000, 
25,  2.298887, 		2.296858, 		0.119000, 
26,  2.299140, 		2.296767, 		0.119000, 
27,  2.299146, 		2.296896, 		0.127000, 
28,  2.298810, 		2.296605, 		0.119000, 
29,  2.298901, 		2.296624, 		0.119000, 
30,  2.299147, 		2.296642, 		0.119000, 
31,  2.298707, 		2.296349, 		0.119000, 
32,  2.298629, 		2.296228, 		0.119000, 
33,  2.298249, 		2.296247, 		0.130000, 
34,  2.298625, 		2.296135, 		0.119000, 
35,  2.298652, 		2.296401, 		0.119000, 
36,  2.298010, 		2.296052, 		0.121000, 
37,  2.298564, 		2.296285, 		0.123000, 
38,  2.298418, 		2.295857, 		0.194000, 
39,  2.298121, 		2.296167, 		0.129000, 
40,  2.297697, 		2.296288, 		0.123000, 
41,  2.298074, 		2.295818, 		0.119000, 
42,  2.297851, 		2.295859, 		0.145000, 
43,  2.297954, 		2.295414, 		0.119000, 
44,  2.297821, 		2.295552, 		0.119000, 
45,  2.297737, 		2.295683, 		0.186000, 
46,  2.297546, 		2.295898, 		0.158000, 
47,  2.297646, 		2.295357, 		0.120000, 
48,  2.297933, 		2.295814, 		0.145000, 
49,  2.297524, 		2.295055, 		0.119000, 
50,  2.297059, 		2.295281, 		0.119000, 
51,  2.297594, 		2.295191, 		0.119000, 
52,  2.297095, 		2.294954, 		0.119000, 
53,  2.296920, 		2.294975, 		0.138000, 
54,  2.297227, 		2.295047, 		0.119000, 
55,  2.296999, 		2.294805, 		0.188000, 
56,  2.297030, 		2.294708, 		0.125000, 
57,  2.296965, 		2.295170, 		0.119000, 
58,  2.296552, 		2.294948, 		0.119000, 
59,  2.296687, 		2.294213, 		0.119000, 
60,  2.296640, 		2.294478, 		0.119000, 
61,  2.296780, 		2.294832, 		0.119000, 
62,  2.296838, 		2.294524, 		0.119000, 
63,  2.296678, 		2.294658, 		0.132000, 
64,  2.296348, 		2.294103, 		0.139000, 
65,  2.295943, 		2.294293, 		0.120000, 
66,  2.296509, 		2.294423, 		0.119000, 
67,  2.296076, 		2.294620, 		0.125000, 
68,  2.295959, 		2.294171, 		0.119000, 
69,  2.295718, 		2.294225, 		0.120000, 
70,  2.295663, 		2.293712, 		0.119000, 
71,  2.295927, 		2.293834, 		0.129000, 
72,  2.296079, 		2.293930, 		0.123000, 
73,  2.295599, 		2.293742, 		0.204000, 
74,  2.295465, 		2.293764, 		0.124000, 
75,  2.295486, 		2.293349, 		0.119000, 
76,  2.295203, 		2.293615, 		0.126000, 
77,  2.295339, 		2.293590, 		0.215000, 
78,  2.295228, 		2.293758, 		0.119000, 
79,  2.295128, 		2.293663, 		0.126000, 
80,  2.295468, 		2.292940, 		0.195000, 
81,  2.295209, 		2.293190, 		0.125000, 
82,  2.294869, 		2.293035, 		0.120000, 
83,  2.294710, 		2.293238, 		0.169000, 
84,  2.294974, 		2.293137, 		0.155000, 
85,  2.294818, 		2.293034, 		0.119000, 
86,  2.294674, 		2.292477, 		0.119000, 
87,  2.294645, 		2.293095, 		0.166000, 
88,  2.294344, 		2.292792, 		0.219000, 
89,  2.294249, 		2.292247, 		0.119000, 
90,  2.294299, 		2.292579, 		0.119000, 
91,  2.294086, 		2.292520, 		0.119000, 
92,  2.294138, 		2.292530, 		0.261000, 
93,  2.294148, 		2.292312, 		0.250000, 
94,  2.293792, 		2.291911, 		0.119000, 
95,  2.293988, 		2.292110, 		0.119000, 
96,  2.293886, 		2.292425, 		0.286000, 
97,  2.293924, 		2.291836, 		0.119000, 
98,  2.293655, 		2.292346, 		0.210000, 
99,  2.293678, 		2.291939, 		0.178000, 
100,  2.293507, 		2.291903, 		0.126000, 
